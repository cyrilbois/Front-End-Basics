# 了解 GPT

## 前置知识

### NLP（Natural Language Processing）

NLP 全称自然语言处理技术，它是一种人工智能技术，旨在解决计算机与人类语言之间的交互问题。

NLP 技术的目标是让计算机能够理解、分析、处理、生成和对话自然语言。

### 深度学习

深度学习是一种机器学习算法，其基于人工神经网络和深度神经网络的思想，可以有效地解决图像和语音识别、自然语言处理、机器翻译和预测等任务。

### GPT（Generative Pre-trained Transformer）

GPT 全称：生成式预训练 Transformer

#### Generative（生成式）

GPT 是一种单向的语言模型，也叫自回归模型，即通过前面的文本预测后面的词，训练时以预测能力为主，只根据前文的信息生成后文。

延伸：还有一种语言模型代表 Bert，是双向语言模型，进行文本预测时会结合前文后文信息，以“完形填空”的方式进行文本预测。

#### Pre-trained（预训练）

预训练让模型学习到一些通用的特征和知识

#### Transformer

Transformer 是一种基于编码器和解码器结构的神经网络模型。

最初由 Google 在 2017 年提出，用于自然语言处理（NLP）领域。Transformer 是一种基于自注意力机制（self-attention mechanism）的模型，可以在输入序列中进行全局信息的交互和计算，从而获得比传统循环神经网络更好的长距离依赖建模能力。

## GPT 发展

- GPT1：2018 年发布，1.17 亿参数，5GB 训练数据
  - 架构：采用了 Transfomer 架构中 decoder 部分，无监督学习以及有监督训练，下游可针对不同任务进行微调
- GPT2：2019 年发布，15 亿参数，40GB 训练数据，
- 架构：用了 Transfomer 架构中 decoder 部分，强化无监督学习能力，提出了 FewShot 少样本学习思想，希望模型自己能够理解输入的任务并执行
- GPT3：2020 年发布，沿用 GPT 2 的架构，区别在于超大规模训练量（钞能力），1750 亿参数，45TB 训练数据
- GPT3.5（ChatGPT）：基于 GPT3 同样的参数和训练数据，引入更多的对话，代码训练数据，引入强化学习机制和奖励模型机制，使得模型有能力根据人类的提示生成符合人类偏好的文本

### 零样本，单样本，少样本学习

传统语言模型中，通常的做法是在一个预训练模型通过微调来适应不同的下游任务。在 GPT 中提出了「少样本学习（Few-Shot）」概念。

少样本学习的工作方式是给出 K 个上下文和完成结果的示例，然后给出一个上下文的最终示例，模型需要提供完成结果。单样本只给出一个示例，模型即可以完成任务。而零样本则是不需要给出示例，直接让语言模型执行相应任务。

零样本，单样本，少样本之间区别，区别在于给出示例的多少。零样本是不给出示例直接让模型执行任务

## 底层原理

ChatGPT 可以类比为学说话的鹦鹉，它没有意识、没有欲望、没有情绪，甚至都不理解自己说了什么。

它的实质功能（原理）是“单字接龙”。给他任意长度的**上文**，它会用自己的**模型**生成下一个字。然后再用这个字跟之前的上文组成**新的上文**，再生成下一个字，不断重复，就可以生成任意长的下文了，这种方式称为自回归生成。这就是 ChatGPT 回答问题的方式。

从上面的描述可以看出，ChatGPT 的核心是**上文**和**模型**，模型的核心是**参数**。模型的参数是通过**训练**得到的，训练的核心是**数据**。

通俗解释：ChatGPT 从根本上始终要做的是，针对它得到的任何文本产生“合理的延续”。这里所说的“合理”是指，“人们在看到诸如数十亿个网页上的内容后，可能期待别人会这样写”。

### GPT 的训练过程概述

- 收集数据：收集大量的文本数据（GPT3 是 45TB），例如维基百科、小说、新闻文章等。
- 分词和编码：对文本数据进行分词和编码，将其转换成数字形式，以便于计算机进行处理。
- 预训练：使用 Transfomer 架构中 decoder 部分对分词后的数据进行预训练，预训练的目标是让 GPT 能够根据给定的上文预测出下一个单词。在这个过程中，GPT 能够**学习**到语言的结构和规律，从而提高其语言的理解和生成能力。
  - 训练的目的是学习，而不是记忆。是为了应对没有记忆过的内容（记忆过的内容可以理解为数据库已经存储过的内容）时使用学习到的通用规律生成合理的内容。这种举一反三的目的也叫做泛化。
- 微调：对预训练好的 GPT 进行微调，使其能够更好地适应特定任务。例如：在对话生成任务中，使用对话数据集对 GPT 进行微调，能使其更高的生成自然流畅的对话内容
- 验证和评估：使用验证集和评估指标来测试 GPT 的性能，如果性能不足，可以重新调整模型参数或者增加更多的训练数据，以提高模型性能。

GPT 的训练过程就是一个迭代的过程，需要不断地收集数据、预处理数据、预训练模型、微调模型、并对模型进行验证和评估，以不断提高模型性能。

通俗解释：ChatGPT（或者说它基于的 GPT-3 网络）到底是在做什么呢？它的总体目标是，根据所接受的训练（查看来自互联网的数十亿页文本，等等），以“合理”的方式续写文本。所以在任意给定时刻，它都有一定量的文本，而目标是为要添加的下一个标记做出适当的选择。

## 预测的实质

GPT 根据上文预测下一个词时会列出随后可能出现的词及其出现的“概率”（按“概率”从高到低排列），比如写一篇文章时，它实质上只是在一遍又一遍地询问“根据目前的文本，下一个词应该是什么”，并且每次都添加一个词。

每一步都会得到一个带概率的词列表。但它应该选择将哪一个词添加到正在写作的文章中呢？有人可能认为应该选择“排名最高”的词，即分配了最高“概率”的词。然而，这里出现了一点儿玄学的意味。如果我们总是选择排名最高的词，通常会得到一篇非常“平淡”的文章，完全显示不出任何“创造力”（有时甚至会一字不差地重复前文，为什么会这样暂时没有科学解释）。但是，如果有时（随机）选择排名较低的词，就会得到一篇“更有趣”的文章。

这里存在随机性意味着，如果我们多次使用相同的提示(prompt)，每次都有可能得到不同的文章。而且，符合玄学思想的是，有一个所谓的“温度”（Temperature）参数来确定低排名词的使用频率。

## chatGPT 的三步训练

### 涌现的能力

## ChatGPT 的缺点

### 胡编混淆

为了能应对「未被记忆的情况」，它会学习语言单位（如单词、短语、句子等）之间的规律，用「学到的规律」来成回答，然而，这也意味着如果出现了「实际不同但碰巧符合同一个规律」的内容，模型就可能混淆它。

最直接的结果是：若「现实中不存在内容」刚好符合「它从训练材料中学到的规律」，那 ChatGPT 就有可能对「不存在内容」进行「合乎规律的混合捏造」。

### 无法直接增删改查

不论是 ChatGPT 「所记住的信息」，还是「所学到的规律」，都是以同一个模型的形式来表达的，因此我们无法像操作数据库那样，对这些内容直接进行增删改查。

这会导致两个具体问题：

第一：由于我们很难理解它所建构的规律，又无法直接查看它记住了什么、学到了什么，只能通过多次提问来评估和猜测它的所记所学，其决策缺乏可解释性，这难免会在使用时带来安全风险。

第二：由于只能通过再次调整模型（即再次训练）来增加、删除或修改它的所记所学，这难免在更新时会降低效率。

## 未来影响

## 如何应对

## 不同人、职业、角度对 GPT 的理解

- 数据产品经理：[大白话讲清楚 ChatGPT](https://mp.weixin.qq.com/s/tri0OINMaOxYeqSk8iFesg)
- 研发：[初探 chatgpt](https://mp.weixin.qq.com/s/nUgoxyLpYOdUzCzyjrs7xw)
- [详解｜程序员如何适应 AI 时代的新需求](https://mp.weixin.qq.com/s/_qKk7KDsAGbR-jfvwlZULQ)

## 其他相关

## 国内使用 AI

- [在中国国内如何购买 ChatGPT Plus](https://www.digitalnomadlc.com/how-to-buy-chatgptplus/)

## 文章

- [ChatGPT 原理探索](https://juejin.cn/post/7218048201982787645)
- [大白话讲清楚 ChatGPT](https://mp.weixin.qq.com/s/tri0OINMaOxYeqSk8iFesg)
- [初探 chatgpt](https://mp.weixin.qq.com/s/nUgoxyLpYOdUzCzyjrs7xw)
